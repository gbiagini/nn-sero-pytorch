{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn-sero-fastai.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkq4LCKdioDlr/M9zsE5do"},"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit ('nn-sero': conda)","metadata":{"interpreter":{"hash":"b79afd0ea3ce5052384881417bb90f3c12217c7284099b2cf876c2df3a9ffbc1"}}}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#base_dir = '/home/gbiagini/dev/nn-sero-pytorch/'\n","base_dir = './'\n","\n","import pandas as pd\n","import numpy as np\n","from fastai import *\n","from fastai.tabular import *\n","#from parse import _file_handler\n","from tqdm import tqdm"]},{"cell_type":"code","metadata":{"id":"_fy3M308ncDD","executionInfo":{"status":"ok","timestamp":1604593459232,"user_tz":360,"elapsed":204996,"user":{"displayName":"David Biagini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvQqurTVavFGQKWkJuo8nuBGfW8PKMTayRJ1h4hQ=s64","userId":"18170855662239852923"}},"outputId":"b54e2718-3ed9-40f2-c481-41575b07fcf4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","# _file_handler()\n","\n","#loci = ['A', 'B', 'C', 'DPB1', 'DQB1', 'DRB1']\n","loci = [\"A\"]\n","epoch = { \"A\":26, \"B\":15, \"C\":13, \"DPB1\":13, \"DQB1\":20, \"DRB1\":13 }\n","layer = { \"A\":[1500], \"B\":[2500], \"C\":[1500], \"DPB1\":[1500], \"DQB1\":[2000], \"DRB1\":[1500] }\n","\n","\n","for locus in loci:\n","  \n","  AAs = []\n","  #tng_df = pd.read_csv(base_dir + 'RSNNS_fixed/training/' + locus + '_train.csv')\n","  #tst_df = pd.read_csv(base_dir + 'RSNNS_fixed/testing/' + locus + '_test.csv')\n","  #val_df = pd.read_csv(base_dir + 'RSNNS_fixed/training/' + locus + '_validation.csv')\n","  tng_df = pd.read_csv(base_dir + 'old_sets/train/' + locus + '_train.csv')\n","  tst_df = pd.read_csv(base_dir + 'old_sets/test/' + locus + '_test.csv')\n","  val_df = pd.read_csv(base_dir + 'old_sets/train/' + locus + '_validation.csv')\n","  tng_idx = len(tng_df)\n","  val_idx = len(val_df) + 1\n","  tst_idx = len(tst_df)\n","  tbatch = tng_idx // 2\n","  if (tbatch <= 1):\n","    tbatch = tng_idx // 2\n","  vbatch = val_idx // 2\n","  if (vbatch <= 1):\n","    vbatch = val_idx // 2\n","  \n","  df = tng_df.append(val_df)\n","\n","  for each in tng_df:\n","    if (each != 'allele') & (each != 'serology'):\n","      AAs.append(each)\n","\n","  dep_var = 'serology'\n","  cat_names = ['allele'] + AAs\n","  #procs = [FillMissing, Categorify]\n","\n","\n","  cat_names = ['allele'] + AAs\n","  test = TabularList.from_df(tst_df, path=Path(''), cat_names=cat_names)\n","  \n","  data = (TabularList.from_df(df=df, path=Path(''), procs=procs, cat_names=cat_names)\n","                              .split_by_idx(list(range(tng_idx,val_idx)))\n","                              .label_from_df(cols=dep_var, label_delim=';')\n","                              .add_test(test)\n","                              .databunch(bs=tbatch, val_bs=vbatch))\n","  '''\n","  data = (TabularList.from_df(df=df, path=Path(''), procs=procs, cat_names=cat_names)\n","                              .split_by_idx(list(range(tng_idx,val_idx)))\n","                              .label_from_df(cols=dep_var, label_delim=';')\n","                              .add_test(test)\n","                              .databunch(bs=tng_idx, val_bs=val_idx))\n","  '''\n","  acc_02 = partial(accuracy_thresh, thresh=0.99)\n","  f_score = partial(fbeta, thresh=0.51)\n","\n","  pre_vote = {}\n","  avg_pred = {}\n","  all_models = []\n","\n","  for n in range(1,11):\n","    learn = tabular_learner(data, opt_func = optim.SGD, layers=layer[locus], metrics=[acc_02, f_score])\n","    print(data.classes)\n","\n","    lr = 0.5\n","    #learn.recorder.plot(suggestion=True)\n","\n","    #learn.fit(epoch[locus], lr)\n","    #learn.fit_one_cycle(epoch[locus], lr)\n","    learn.fit_one_cycle(epoch[locus], max_lr=slice(lr))\n","    learn.model\n","    #learn.recorder.plot_losses()\n","\n","    test_id = list(tst_df['allele'])\n","\n","    classes = data.classes\n","    predictions = []\n","    print(classes)\n","\n","   \n","    for i in tqdm(range(0,tst_idx)):\n","      category = str(learn.predict(tst_df.iloc[i], thresh=0.51)[0])\n","      sero = category.strip('MultiCategory ')\n","      sero = sero.replace(';',' ')\n","      sero = sero.replace('a','')\n","      predictions.append(sero.split())\n","    \n","\n","    pre_vote = {test_id[j]: str(predictions[j]) for j in range(len(test_id)) }\n","    avg_pred[str(n)] = pre_vote\n","    \n","\n","  avg_frame = pd.DataFrame.from_dict(avg_pred)\n","  mode = avg_frame.mode(axis=1)\n","  rmode = mode[0]\n","  rmode = pd.DataFrame(rmode)\n","  rmode = rmode.reset_index()\n","  rmode.columns=['allele', 'serology']\n","\n","  #output_preds = pd.DataFrame({'allele': test_id, 'serology': predictions})\n","  rmode.to_csv(base_dir + 'predictions/' + locus + '_predictions.csv', index=False)\n"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'TabularList' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7827baa55642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mcat_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'allele'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   data = (TabularList.from_df(df=df, path=Path(''), procs=procs, cat_names=cat_names)\n","\u001b[0;31mNameError\u001b[0m: name 'TabularList' is not defined"]}]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["HLA-A Similar: 1620\n","HLA-A Different: 72\n","HLA-A Concordance: 95.74468085106383%\n","HLA-B Similar: 1776\n","HLA-B Different: 496\n","HLA-B Concordance: 78.16901408450704%\n","HLA-C Similar: 878\n","HLA-C Different: 443\n","HLA-C Concordance: 66.46479939439818%\n","HLA-DPB1 Similar: 141\n","HLA-DPB1 Different: 16\n","HLA-DPB1 Concordance: 89.80891719745223%\n","HLA-DQB1 Similar: 245\n","HLA-DQB1 Different: 31\n","HLA-DQB1 Concordance: 88.76811594202898%\n","HLA-DRB1 Similar: 876\n","HLA-DRB1 Different: 128\n","HLA-DRB1 Concordance: 87.25099601593625%\n"]}],"source":["  loci = ['A', 'B', 'C', 'DPB1', 'DQB1', 'DRB1']\n","#loci = ['A']\n","\n","# function to check if value can be an integer - to eliminate excess characters from serology labels\n","def checkInt(x):\n","    try:\n","        int(x)\n","        return True\n","    except ValueError:\n","        return False\n","\n","\n","for loc in loci:\n","    newDict = {}\n","    simDict = {}\n","    diffDict = {}\n","    oldPredict = {}\n","    newPredict = {}\n","    oldPredFile = base_dir + \"old-predictions/\" + loc + \".chile\"\n","    newPreds = pd.read_csv(base_dir + \"predictions/\" + loc + \"_predictions.csv\")\n","    newPreds = newPreds.set_index('allele')\n","    newPreds = newPreds.to_dict()\n","    newPredict = newPreds[\"serology\"]\n","    for nKey in newPredict.keys():\n","        adjustMe = newPredict[nKey]\n","        adjustMe = adjustMe.replace('[','')\n","        adjustMe = adjustMe.replace(']','')\n","        adjustMe = adjustMe.replace(' ','')\n","        adjustMe = adjustMe.replace(\"'\",'')\n","        adjustMe = adjustMe.split(',')\n","        newPredict[nKey] = [x.strip('a') for x in adjustMe if checkInt(x)]\n","    with open(oldPredFile, \"r\") as handle:\n","        for line in handle:\n","            if line.find('%') == -1:\n","              next\n","            else:\n","                line = line.split()\n","                if line == []:\n","                    next\n","                else:\n","                    line[:] = [x for x in line if (x != '[100.00%]')]\n","                    allele = loc + \"*\" + str(line[0][:-1])\n","                    oldPredict[allele] = line[1:]\n","\n","\n","    for each in oldPredict.keys():\n","        allDict = {}\n","        allDict[\"Allele\"] = each\n","        allDict[\"Old Assignment\"] = oldPredict[each]\n","        allDict[\"New Assignment\"] = newPredict[each]\n","        if each not in newPredict.keys():\n","          next\n","        elif set(newPredict[each]) != set(oldPredict[each]):\n","            diffDict[each] = allDict\n","        elif set(newPredict[each]) == set(oldPredict[each]):\n","            simDict[each] = allDict\n","    diffFrame = pd.DataFrame.from_dict(diffDict)\n","    diffFrame = diffFrame.transpose()\n","    diffFrame.to_csv(base_dir + \"comparison/\" + loc + \"_compfile.csv\", index=False)\n","    simFrame = pd.DataFrame.from_dict(simDict)\n","    simFrame = simFrame.transpose()\n","    simFrame.to_csv(base_dir + \"comparison/\" + loc + \"_similar.csv\", index=False)\n","    \n","\n","    for allele in newPredict.keys():\n","        allDict = {}\n","        allDict[\"Allele\"] = allele\n","        allDict[\"Serologic Assignment\"] = newPredict[allele]\n","        if allele not in oldPredict.keys():\n","            newDict[allele] = allDict\n","    newFrame = pd.DataFrame.from_dict(simDict)\n","    newFrame = newFrame.transpose()\n","    newFrame.to_csv(base_dir + \"comparison/\" + loc + \"_newsies.csv\", index=False)\n","\n","    simLen = len(simFrame)\n","    diffLen = len(diffFrame)\n","    print(\"HLA-\" +loc+ \" Similar: \" + str(simLen))\n","    print(\"HLA-\" +loc+ \" Different: \" + str(diffLen))\n","\n","    concordance = (simLen / (simLen + diffLen)) * 100\n","    print(\"HLA-\" +loc+ \" Concordance: \" + str(concordance) + \"%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}